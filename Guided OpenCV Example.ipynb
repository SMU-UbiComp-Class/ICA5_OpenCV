{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import itertools\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Video Capture and Analysis\n",
    "In the below example, you can use the windows from highgui to change what part of the code is getting implemented. Press the digits 1-9 to change which conditional is getting processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vc opened, getting first frame\n",
      "releasing...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "section = 0\n",
    "\n",
    "# setup some windows for viewing\n",
    "cv2.namedWindow(\"demowin1\")\n",
    "cv2.namedWindow(\"demowin2\")\n",
    "cv2.startWindowThread()\n",
    "\n",
    "# open the video card for capture\n",
    "vc = cv2.VideoCapture(0)\n",
    "\n",
    "if vc.isOpened():  # try to get the first frame\n",
    "    print (\"vc opened, getting first frame\")\n",
    "    rval, frame = vc.read()\n",
    "    # this will likely fail the first time\n",
    "    # the webcam often needs some time to open fully\n",
    "    key = 0\n",
    "else:\n",
    "    print (\"vc not open, exiting\")\n",
    "    key = 27\n",
    "\n",
    "while key != 27 and vc.isOpened():  # the escape key and the capture device is open\n",
    "    rval, frame = vc.read()\n",
    "    key = cv2.waitKey(10)\n",
    "\n",
    "    # interpret the input key, on top number line of keyboard\n",
    "    if ord('0') <= key <= ord('7'):\n",
    "        section = key - ord('0')  # press 0, 1, 2, ... 9\n",
    "\n",
    "    if rval and frame is not None:\n",
    "        frame = cv2.pyrDown(frame)  # make smaller immediately\n",
    "\n",
    "        if section == 0:\n",
    "            pass  # just display the WebCam image\n",
    "\n",
    "        elif section == 1:\n",
    "            # get the width and the height and the depth\n",
    "            h, w, d = frame.shape\n",
    "            i = int(h / 2)\n",
    "            j = int(w / 2)\n",
    "\n",
    "            # slow access\n",
    "            t = time.time()\n",
    "            for iterate in range(0, 10000):\n",
    "                b = frame[i, j, 0]\n",
    "                g = frame[i, j, 1]\n",
    "                r = frame[i, j, 2]\n",
    "            str1 = \"B1:%d, G1:%d, R1:%d, time=%.5f\" % (b, g, r, time.time() - t)\n",
    "\n",
    "            # speed up access using NumPy accelerations\n",
    "            t = time.time()\n",
    "            for iterate in range(0, 10000):\n",
    "                b = frame.item(i, j, 0)\n",
    "                g = frame.item(i, j, 1)\n",
    "                r = frame.item(i, j, 2)\n",
    "            str2 = \"B2:%d, G2:%d, R2:%d, time=%.5f\" % (b, g, r, time.time() - t)\n",
    "\n",
    "            # set the value\n",
    "            for x in itertools.product(range(i - 10, i + 10), range(j - 10, j + 10)):\n",
    "                frame.itemset(x[0], x[1], 0, 255)  # blue value\n",
    "\n",
    "            cv2.putText(frame, str1, (10, 80), cv2.FONT_HERSHEY_SIMPLEX, 0.5, [0, 255, 0])\n",
    "            cv2.putText(frame, str2, (10, 100), cv2.FONT_HERSHEY_SIMPLEX, 0.5, [0, 255, 255])\n",
    "\n",
    "        elif section == 2:\n",
    "            # convert to gray\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            cv2.imshow(\"demowin2\", gray)\n",
    "\n",
    "        elif section == 3:\n",
    "            # convert to HSV and then grab the Hue component\n",
    "            hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "            singleChannel = cv2.split(hsv)[0]\n",
    "            cv2.imshow(\"demowin2\", singleChannel)\n",
    "\n",
    "        elif section == 4:\n",
    "            # scaling down an image (can speed things up if your frame rate gets too slow)\n",
    "            small_frame = cv2.pyrDown(frame)\n",
    "            cv2.imshow(\"demowin2\", small_frame)\n",
    "\n",
    "        elif section == 5:\n",
    "            # smoothing with a filter\n",
    "            kernel = cv2.getGaussianKernel(25, 3)\n",
    "            smooth_frame = cv2.filter2D(frame, -1, kernel)\n",
    "            cv2.imshow(\"demowin2\", smooth_frame)\n",
    "\n",
    "        elif section == 6:\n",
    "            # Requires a single-channel image:\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Reduce the image to the edges detected:\n",
    "            gray = cv2.Canny(gray, 50, 100, 3)  # Arbitrarily chosen parameters. See documentation for the meaning\n",
    "            cv2.imshow(\"demowin2\", gray)\n",
    "\n",
    "        elif section == 7:\n",
    "            # Hough Circles:  http://en.wikipedia.org/wiki/Hough_transform\n",
    "\n",
    "            # Requires a single-channel image:\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Want to smooth it to get less noise\n",
    "            kernel = cv2.getGaussianKernel(9, 1)\n",
    "            gray = cv2.filter2D(gray, -1, kernel)\n",
    "\n",
    "            # Detect the circles in the image\n",
    "            circles = cv2.HoughCircles(gray, cv2.HOUGH_GRADIENT, 4, minDist=800,\n",
    "                                       param1=300, param2=100, minRadius=30, maxRadius=70)\n",
    "            if circles is not None:\n",
    "                circles = np.uint16(np.around(circles[0]))\n",
    "                # Iterate through the list of circles found by cvHoughCircles()\n",
    "                for c in circles:\n",
    "                    # It has the format: [center_x, center_y, radius]\n",
    "                    # lets draw them\n",
    "                    center = (c[0], c[1])  # center of the circle\n",
    "                    rad = c[2]  # radius of the circle\n",
    "                    cv2.circle(frame, center, rad, (0, 255, 0), 1)\n",
    "\n",
    "                    # # There's lots of drawing commands you can use!\n",
    "                    # Here is some c++ code to get you on the right track:\n",
    "                    # CvFont font;\n",
    "                    # cvInitFont(&font, CV_FONT_HERSHEY_SIMPLEX, 1, 1, 0.0, 1, 8);\n",
    "                    # cvCircle( frame, cvPoint(cvRound(p[0]),cvRound(p[1])), cvRound(p[2]), CV_RGB(255,0,0), 3, 8, 0 );\n",
    "                    # cvPutText( frame, \"Circle\", cvPoint(cvRound(p[0]),cvRound(p[1])), &font, CV_RGB(255,0,0) );\n",
    "\n",
    "        # we have an image to process\n",
    "        cv2.putText(frame, \"Section = \" + str(section), (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.5, [0, 255, 0])\n",
    "        cv2.imshow(\"demowin1\", frame)\n",
    "\n",
    "print('releasing...')\n",
    "cv2.waitKey(1)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Color\n",
    "This will isolate similar hues in the image. You can adjust the threshold you are using by pressing `u` and `d` to increase or decrease the value of the threshold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vc is open!!\n",
      "releasing...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# setup some windows for viewing\n",
    "cv2.namedWindow(\"WebCam\")\n",
    "cv2.namedWindow(\"Hue\")\n",
    "cv2.startWindowThread()\n",
    "\n",
    "vc = cv2.VideoCapture(0)\n",
    "\n",
    "if vc.isOpened():\n",
    "    print (\"vc is open!!\")\n",
    "    return_value, frame = vc.read()\n",
    "\n",
    "h_range = 30\n",
    "key = -1\n",
    "while key != 27 and vc.isOpened():\n",
    "    return_value, frame = vc.read()\n",
    "\n",
    "    if frame is not None:\n",
    "\n",
    "        height, width, depth = frame.shape\n",
    "\n",
    "        frame = cv2.pyrDown(frame)\n",
    "\n",
    "        hsv_img = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "        h, s, v = cv2.split(hsv_img)\n",
    "\n",
    "        h = cv2.inRange(h, h_range, h_range+10)\n",
    "        h_binary = h.copy()\n",
    "        _, contours, hierarchy = cv2.findContours(h_binary, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        if contours is not None and len(contours) > 0:\n",
    "            for cnt in contours:\n",
    "                area = cv2.contourArea(cnt)\n",
    "                # bb   = cv2.boundingRect(cnt)\n",
    "\n",
    "                pt = tuple(cnt[0][0])\n",
    "                if area > 100:\n",
    "                    cv2.putText(h, str(area), pt, cv2.FONT_HERSHEY_SIMPLEX, 0.25, 255)\n",
    "\n",
    "        cv2.putText(h, str(h_range), (10, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, 128)\n",
    "        cv2.imshow(\"WebCam\", frame)\n",
    "        cv2.imshow(\"Hue\", h)\n",
    "\n",
    "    key = cv2.waitKey(10)\n",
    "    if key == ord('u'):\n",
    "        h_range += 1\n",
    "    elif key == ord('d'):\n",
    "        h_range -= 1\n",
    "\n",
    "print('releasing...')\n",
    "cv2.waitKey(1)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Skin and Understanding Hands\n",
    "This will isolate skin in an image based on a calibration of the color. Hold you hand over the \"squares\" in the \"input\" image window and press `c` to calibrate the software. Once calibrated, the system will attempt to segment the skin in the image (based on the color variation it observed from your calibration image). Then it will attempt to find the convex hull and convex deformations of the skin to estimate likely locations of finger tips. \n",
    "\n",
    "To perform a new calibration, just press `u` to undo the previsou calibration. Then you can repeat the above steps as needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video opened, getting first frame\n",
      "[(163.0, 45.0, 148.0), (159.0, 45.0, 163.5), (170.0, 102.0, 120.0), (156.0, 44.0, 165.0), (164.0, 47.0, 143.0), (166.0, 67.0, 139.0), (158.0, 42.0, 156.0)]\n",
      "[(175.0, 95.5, 127.0), (174.0, 87.0, 126.0), (139.0, 33.0, 205.0), (137.0, 35.0, 162.0), (168.0, 63.0, 143.0), (166.0, 62.0, 131.0), (165.0, 53.0, 146.0)]\n",
      "releasing...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "ESC_KEY = 27  # for allowing the user to exit the program\n",
    "C_KEY = ord('c')\n",
    "U_KEY = ord('u')\n",
    "\n",
    "import cv2\n",
    "import cvhelper  # some helper files written by eclarson\n",
    "# setup some windows for viewing\n",
    "cv2.namedWindow(\"input\")\n",
    "cv2.namedWindow(\"output\")\n",
    "cv2.startWindowThread()\n",
    "\n",
    "def set_patches(img_in):\n",
    "    height, width, depth = img_in.shape\n",
    "\n",
    "    patches = [(width / 2, 3 * height / 4), (width / 2, height / 2), (width / 2, height / 4),\n",
    "               (width / 2 + 45, 5 * height / 8), (width / 2 - 10, 5 * height / 8 + 10),\n",
    "               (width / 2 + 25, 5 * height / 8 - 20), (width / 2 - 35, 5 * height / 8)]\n",
    "\n",
    "    return patches\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)  # video capture on default input stream\n",
    "if cap.isOpened():\n",
    "    print (\"Video opened, getting first frame\")\n",
    "    ret, img = cap.read()  # get a frame from the video card\n",
    "\n",
    "k = -1\n",
    "calibrated = False\n",
    "while cap.isOpened():\n",
    "    ret, img = cap.read()  # get a frame from the video card\n",
    "    if ret and (img is not None):\n",
    "        img = cvhelper.pre_process(img)\n",
    "        hsv_img = cvhelper.convert_color(img)\n",
    "        hand_patches = set_patches(img)\n",
    "\n",
    "        if k == C_KEY:\n",
    "            # user initiated a calibrate command\n",
    "            median_values = cvhelper.find_median_colors(hsv_img, hand_patches, 10)\n",
    "            calibrated = True\n",
    "            print (median_values)\n",
    "\n",
    "        elif k == U_KEY:\n",
    "            calibrated = False\n",
    "\n",
    "        if not calibrated:\n",
    "            # show the user where to place their hand\n",
    "            img = cvhelper.set_img_boxes(img, hand_patches, 10)\n",
    "        else:\n",
    "            # process where we think the hand is\n",
    "            skin_img = cvhelper.segment_skin(hsv_img, median_values)\n",
    "            cv2.imshow('skin', skin_img)\n",
    "            hsv_img = cvhelper.find_contours(skin_img)\n",
    "\n",
    "        cv2.imshow('output', hsv_img)\n",
    "        cv2.imshow('input', img)\n",
    "\n",
    "    # get possible text input from the open figures\n",
    "    # if a user presses a key, it will show up here\n",
    "    k = cv2.waitKey(10)\n",
    "    if k == ESC_KEY:\n",
    "        break\n",
    "\n",
    "print('releasing...')\n",
    "cv2.waitKey(1)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
